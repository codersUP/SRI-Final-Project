\documentclass{llncs}

\usepackage{llncsdoc}

%
\title{Proyecto de Sistemas de Recuperación de Información}

\author{Enrique Martínez González \and Carmen Irene Cabrera Rodríguez \and Osmany Pérez Rodríguez}
\institute{C512}



\begin{document}

\maketitle

\begin{abstract}
    La localización de materiales de naturaleza no estructurada para satisfacer una necesidad de información en una larga colección almacenada es una actividad cada día más importante. Con el fin de lograr este objetivo se ha desarrollado un sistema de recuperación de información basándose en la utilización de los modelos vectorial y booleano capaces de encontrar documentos interrelacionados con una consulta planteada mediante una interfaz visual web. Se ha desarrollado de igual forma un mecanismo para poder expandir la consulta permitiendo apreciar posibles modificaciones de esta con el objetivo de tener una mayor efectividad en la búsqueda de información. Finalmente se aprecian las comparativas de los modelos implementados probados en dos sets de datos distintos.
\end{abstract}

\keywords{Sistema de Recuperación de Información, modelo vectorial, modelo booleano, consulta expandida}


\newpage
\tableofcontents
\newpage


\section{Introducción}
En la actualidad, dado el auge que ha tenido el Internet, existe una enorme disponibilidad de información en línea y documentos, que resulta abrumadora para los usuarios. De ahí que sea interés de muchos investigadores desarrollar una herramienta automática que permita la obtención de información relevante a una consulta determinada. Esta consulta debe ser resuelta rápidamente obteniendo documentos útiles acerca del tema solicitado.

Esta resulta una tarea no trivial y difícil de llevar a cabo; pues, mientras las personas pueden leer un documento para comprenderlo y ver acerca de qué contenido trata y luego decidir si es relevante a la consulta; la computadora carece de conocimiento humano y de la capacidad del lenguaje.

Las primeras incursiones en esta área, datan de mitades del siglo XX, comenzando con estudios utilizando como set de datos la colección Cranfield, utilizando un gran número de técnicas distintas cuyo rendimiento fue bueno. Desde entonces, muchos trabajos han sido publicados para abordar este problema, pudiendo observar un aumento significativo de las investigaciones sobre el tema a partir de 1992. Son numerosos los enfoques que se han llevado a cabo y que son aplicados ampliamente en
varios dominios. El presente trabajo tiene como propósito tratar los enfoques planteados en el modelo booleano y el modelo vectorial para la obtención de documentos relevantes, además de plantear un algorítmo de expansión de consulta.

\section{Modelo de Recuperación de Información}

Se puede definir un modelo de recuperación de información como una cuádrupla en donde se tiene un conjunto de representaciones lógicas de los documento de la colección al que llamaremos D, un conjunto de las representaciones lógicas de la consulta realizada por el usuario al que llamaremos Q, para modelar las representaciones de los documentos y las consultas, y sus relaciones se utiliza un framework que llamaremos F y finalmente una función que es capaz de ordenar de alguna manera los documentos pertencientes a D relevantes ante la consulta Q, esta función posee el nombre de ranking a la que llamaremos R.

\subsection{Representación de documentos}

Para la realización de este proyecto se han utilizado 3 conjuntos de documentos, dos de ellos para la evaluación de la calidad de los modelos, y el tercero para la elavoración de una herramienta visual que permite al usuario realizar consultas para probar de forma interactiva la herramienta desarrollada. Los dos conjuntos de documentos utilizados para la evaluación poseen el nombre de {\bfseries Cranfield} y {\bfseries Vaswani}, estos poseen 1400 y 11000 documentos respectivamente, ambos con temática de resúmenes científicos.

La representación de estos documentos es obtenida mediante un proceso de construcción de índices y de índices inversos. En el índice se almacena la información de los términos que aparecen en cada documento, y la frecuencia con la que aparece, además de aprobechar este mismo cómputo para calcular múltiples valores que serán posteriormente utilizados en el modelo vectorial, este cómputo adelantado permitirá la obtención de documentos relevantes a consultas de manera más rápidas, los detalles se explicarán posteriormente en el artículo. En el índice inverso se almacena por cada término perteneciente al conjunto, en qué documentos este aparece. Resaltar que los terminos utilizados en estos dos cómputos no son todas las palabras que aparecen en los documentos, estas palabras se filtran utilizando la biblioteca {\bfseries Spacy} para tokenizar el documento y después eliminar aquellos tokens que no son de importancia para el procesamiento: signos de puntuación, de monedas, dígitos, espacios, stopwords, y luego transformadas a su forma base utilizando la funcionalidad {\bfseries lemmatise} que posee esta biblioteca.

Con estas representaciones se está comprimiendo un conjunto de documentos en dos diccionarios de {\bfseries Python} que nos permite la rápida inserción y extracción de información acerca de documentos y terminos presentes en el sistema.

\subsection{Representación de consultas}

Los dos conjuntos de documentos planteados anteriormente que fueron utilizados para la evaluación de la calidad de los modelos implementados poseen un conjunto de consultas y para cada una de estas poseen los documentos que son relevantes y su valor de relevancia está determinado por un valor que va de -1 hasta 4, siendo -1 el valor para un documento que no posee mucha relevancia con la consulta y siendo 4 el valor que poseen los documentos con más valor para la necesidad del usuario. {\bfseries Cranfield} posee 225 consultas con un total de 1800 documentos relevantes en total mientras que {\bfseries Vaswani} tiene 93 consultas para un total de 2100 documentos relevantes. Resaltar que estas consultas no están orientadas al modelo booleano ya que no están expresadas mediante el uso de una expresión booleana sobre los términos utilizando las operaciones clásicas como, {\bfseries OR}, {\bfseries AND} y {\bfseries NOT}. Para la comparación de modelos se modificó estos sets de consultas en la evaluación del modelo booleano, susituyendo los espacios entre términos por operadores {\bfseries OR}.

\subsubsection{Modelo Booleano}\

Para la representación de las consultas en el modelo booleano se ha creado un {\bfseries Lexer} y un {\bfseries Parser} utilizando la biblioteca {\bfseries Ply} permitiendo así implementar una gramática para poder leer consultas que son expresiones booleanas con las operaciones definidas anteriormente, para el agrupamiento dentro de la expresión, cumpliendo con la propiedad asociativa y distributiva que poseen las expresiones booleanas se han empleado los signos de corchetes {\bfseries []}. La gramática empleada posee las siguientes reglas:

\begin{verbatim}
  Expr : Expr AND Expr 
  Expr : Expr OR Expr 
  Expr : [ Expr ]
  Expr : NOT Expr
  Expr : Term
  Term : word

  word = r"[a-zA-Z0-9_.,?!'/\(\)-]+"
\end{verbatim}

El lexer, divide en tokens la consulta y desecha aquellos caracteres que no se consideran necesarios. Al mismo tiempo apoyándose en la biblioteca {\bfseries Spacy}, se le aplica la función {\bfseries lemmatise} a cada término, de la misma forma que se le realizó a los documentos, para llevar las palabras a su forma original. El resultado del {\bfseries Parser} es un {\bfseries AST} modificado, que posee toda la información valiosa de la consulta.

\subsubsection{Modelo Vectorial}\

En el modelo vectorial lo primero que se realiza es la tokenización de los términos de la misma forma que se realizó con los documentos en un inicio,
esto se hace con el objetivo de poder utilizar la función {\bfseries lemmatise} de la biblioteca {\bfseries Spacy}. Luego se crea un índice para la consulta, en donde se guarda por cada término la frecuencia con la que este aparece en la interrogante del usuario. Además se aprobecha este momento para realizar cómputo sobre los términos que será utilizado próximamente en la recuperación de documentos del modelo.

\subsection{Framework}\

Para la representación de los documentos se utilizaron los diccionarios de {\bfseries Python}, estos permiten la representación de los términos como un conjunto, y se puede almacenar información como su frecuencia. Además permite la rápida recuperación de estos.

Para la representación de las consultas se emplearon técnicas distintas dependiendo del modelo, en caso del modelo booleano se utilizó un árbol de sintaxis abstracta representado mediante diccionarios de {\bfseries Python}, en los que se almacenaban los hijos de cada nodo y la operación que representaba. En caso del modelo vectorial la consulta se representa mediante un diccionario al igual que los documentos en los que se guarda la frecuencia de cada término dentro de la consulta y otras informaciones que serán explicadas posteriormente.

\subsection{Ranking}
El cómputo que se hizo en la etapa del análisis de los documentos y la consulta es de vital importancia para el rápido desarrollo del cálculo de la interrelación entre estos. En el caso de los documentos se calcula para cada térmio el valor de la frecuencia de un término en el documento, y además se calcula la frecuencia normalizada del término $i$ en el documento $j$ que esta es:

\begin{equation}
    tf_{i, j} = \frac{freq_{i, j}}{max_l freq_{l, j}}
\end{equation}

Como se puede ver, ninguno de los factores en la definición está fuera del conjunto de documentos analizados, por lo que se cálculo se puede desarrollar en esta fase de precómputo. Igualmente sucede con la frecuencia de ocurrencia de un término dentro de todos los documentos de la colección ({\bfseries $idf$}). Con estos dos valores mencionados, $tf$ e $idf$, podemos calcular el peso del término $i$ en el documento $j$ ya que este es:

\begin{equation}
    w_{i, j} = tf_{i, j} * idf_{i}
\end{equation}

Este peso será utilizado en el modelo vectorial. Igualmente se puede realizar cómputo sobre la consulta en cuanto es recibida, calculando el valor del peso del término $i$ en la consulta $q$ con esta con la ecuación:

\begin{equation}
    w_{i, q} = (a + (1 - a) * \frac{freq_{i, q}}{max_l freq_{l, q}}) * log \frac{N}{n_i}
\end{equation}

$N$ es el total de documentos en la colección y $a$ es el término de suavizado, en la evaluación obtenida se utilizó $a$ con un valor de $0.5$.

\subsubsection{Modelo Booleano}\

Recordemos que el resultado de la representación de la consulta en este modelo es un {\bfseries AST}, por lo que sobre este árbol se realiza un recorrido de todos los nodos siguiendo un patrón {\bfseries Visitor} creando el conjunto solución a la consulta utilizando para esto el índice invertido de términos creado. Este conjunto de solución a la consulta es el resultado de ir realizando interesecciones, uniones y diferencias de diferentes conjuntos de documentos durante el recorrido del árbol, cada operación de conjunto aplicada depende de la operación contenida en el nodo visitado, detallar que las hojas del árbol representan los términos de la consulta y son nodos que poseen los conjuntos de documentos en los que aparece este término. Finalmente el nodo raiz del {\bfseries AST} contiene todos los documentos que cumplen con las condiciones presentadas en forma de consulta por el usuario. En caso de este modelo no existe superioridad de un documento relevante sobre otro relevante, sencillamente la relación de relevancia es binaria.

\subsubsection{Modelo Vectorial}\

Es en este modelo donde vamos a hacer uso de todo el precálculo que se hizo sobre los documentos y la consulta, pues aquí la similitud de un documento y una interrogante está dada por el coseno del ángulo entre el vector documento y el vector consulta. Estos vectores están definidos sobre el espacio vectorial de n dimensiones en donde n es la cantidad de términos que se encuentran presentes en todo el sistema. Las componentes de cada vector son binarias, siendo 1 si el término del sistema representado por esa componente se encuentra en el documento o consulta analizado, o siendo 0 en caso contrario. El coseno entre el vector representante del documento $j$ y la consulta $q$ se calcula de la forma:

\begin{equation}
    sim(d_j, q) = \frac{\sum_{i = 1}^n w_{i, j} * w_{i, q}}{\sqrt{\sum_{i = 1}^n w^2_{i, j}} + \sqrt{\sum_{i = 1}^n w^2_{i, q}}}
\end{equation}

Se pudiese definir el peso total de un documento o consulta como la raiz de la sumatoria del cuadrado de los pesos de todos los términos en un documento o consulta, como vemos estos se pueden calcular en la etapa de preprocesamiento de los documentos y la consulta respectivamente, estos cálculos fueron también realizados en estas etapas para agilizar la velocidad de la recuperación de los documentos relevantes.

Luego queda hallar los términos en común entre la consulta y el documento para encontrar el numerador del cálculo del coseno y ya obtendriamos el valor de la similitud entre un documento y una consulta. Mientras mayor valor de similitud, mayor relevancia del documento ante la consulta.

\end{document}